
R version 3.4.0 (2017-04-21) -- "You Stupid Darkness"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ###
> # Bugfixes
> 
> require("gamboostLSS")
Loading required package: gamboostLSS
Loading required package: mboost
Loading required package: parallel
Loading required package: stabs
This is mboost 2.8-0. See 'package?mboost' and 'news(package  = "mboost")'
for a complete list of changes.


Attaching package: 'gamboostLSS'

The following object is masked from 'package:stats':

    model.weights

> require("gamlss")
Loading required package: gamlss
Loading required package: splines
Loading required package: gamlss.data
Loading required package: gamlss.dist
Loading required package: MASS

Attaching package: 'gamlss.dist'

The following object is masked from 'package:mboost':

    Family

Loading required package: nlme
 **********   GAMLSS Version 5.0-1  ********** 
For more on GAMLSS look at http://www.gamlss.org/
Type gamlssNews() to see new features/changes/bug fixes.

> 
> ## subset method was missing if initial mstop = 1
> set.seed(1907)
> x1 <- rnorm(1000)
> x2 <- rnorm(1000)
> x3 <- rnorm(1000)
> x4 <- rnorm(1000)
> x5 <- rnorm(1000)
> x6 <- rnorm(1000)
> mu    <- exp(1.5 + x1^2 +0.5 * x2 - 3 * sin(x3) -1 * x4)
> sigma <- exp(-0.2 * x4 +0.2 * x5 +0.4 * x6)
> y <- numeric(1000)
> for( i in 1:1000)
+     y[i] <- rnbinom(1, size = sigma[i], mu = mu[i])
> dat <- data.frame(x1, x2, x3, x4, x5, x6, y)
> 
> model <- gamboostLSS(y ~ ., families = NBinomialLSS(), data = dat,
+                      control = boost_control(mstop = 1))
> model[10]

	 LSS Models fitted via Model-based Boosting

Call:
gamboostLSS(formula = y ~ ., data = dat, families = NBinomialLSS(),     control = boost_control(mstop = 1))

Number of boosting iterations (mstop):  mu = 10, sigma = 10 
Step size:  mu = 0.1, sigma = 0.1 

Families:

	 Negative Negative-Binomial Likelihood: mu (log link) 

Loss function: -(lgamma(y + sigma) - lgamma(sigma) - lgamma(y + 1) + sigma *  
     log(sigma) + y * f - (y + sigma) * log(exp(f) + sigma)) 
 

	 Negative Negative-Binomial Likelihood: sigma (log link) 

Loss function: -(lgamma(y + exp(f)) - lgamma(exp(f)) - lgamma(y + 1) + exp(f) *  
     f + y * log(mu) - (y + exp(f)) * log(mu + exp(f))) 
 
> 
> 
> ## selected() was broken (didn't call mboost-function)
> stopifnot(all.equal(selected(model),
+                     list(mu = mboost::selected(model[[1]]),
+                          sigma = mboost::selected(model[[2]]))))
> 
> # If the families argument is not specified explicitly in mboostLSS one gets an
> # error in cvrisk.mboostLSS() (spotted by Almond StÃ¶cker).
> # (https://github.com/boost-R/gamboostLSS/issues/9)
> set.seed(1907)
> x1 <- rnorm(1000)
> mu    <- 2*x1
> sigma <- rep(1, 1000)
> y <- numeric(1000)
> for( i in 1:1000)
+        y[i] <- rnorm(1, mean = mu[i], sd=sigma[i])
> dat <- data.frame(x1=x1, y=y)
> ## model with default families
> model <- mboostLSS(y ~ bbs(x1), data = dat, control = boost_control(mstop = 2))
> ## cvrisk.mboostLSS() does not work as families was not specified in model call
> cvr <- try(cvrisk(model, folds = cv(model.weights(model), B=3), trace=FALSE),
+            silent = TRUE)
Warning message:
In make.grid(mstop(object)) :
  Duplicates produced; Only unique values are returned
> if (inherits(cvr, "try-error"))
+     stop("cvrisk does not work if no family was (explicitly) chosen")
> 
> 
> # Make sure that gamlss.dist::BB and gamlss.dist::BI work (spotted by F. Scheipl)
> # (https://github.com/boost-R/gamboostLSS/issues/12)
> set.seed(123)
> n <- 100
> x <- rnorm(n)
> z <- rnorm(n)
> data <- data.frame(y = rbinom(n, p = plogis(x + z), size = 60), x = x, z= z)
> data$ymat <- with(data, cbind(success = data$y, fail = 60 - data$y))
> 
> m1 <- gamlss(ymat ~ x + z, data = data, family = BB)
GAMLSS-RS iteration 1: Global Deviance = 699.795 
GAMLSS-RS iteration 2: Global Deviance = 534.6991 
GAMLSS-RS iteration 3: Global Deviance = 517.8675 
GAMLSS-RS iteration 4: Global Deviance = 517.8664 
GAMLSS-RS iteration 5: Global Deviance = 517.8664 
> m2 <- gamlss(ymat ~ x + z, data = data, family = BI)
GAMLSS-RS iteration 1: Global Deviance = 517.8684 
GAMLSS-RS iteration 2: Global Deviance = 517.8684 
> # same with boosting
> m3 <- glmboostLSS(ymat ~ x + z, data = data, families = as.families("BB"))
> m4 <- glmboost(ymat ~ x + z, data = data, family = as.families("BI"))
Warning message:
In as.families("BI") :
  For boosting one-parametric families, please use the mboost package.
> 
> round(data.frame(BB_gamlss = coef(m1),
+                  BI_gamlss = coef(m2),
+                  BB_gamboostLSS = coef(m3, off2int = TRUE, parameter = "mu"),
+                  BI_gamboostLSS = coef(m4, off2int = TRUE)), 3)
            BB_gamlss BI_gamlss BB_gamboostLSS BI_gamboostLSS
(Intercept)    -0.014    -0.014         -0.006         -0.014
x               1.009     1.009          0.964          1.009
z               0.965     0.965          0.925          0.965
> 
> proc.time()
   user  system elapsed 
   4.39    0.29    5.03 
